<!DOCTYPE html>
<html>
	<head>
		<title>The drum machine of Tao ☯︎ </title>
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<style>
			div {
			margin-bottom: 32px;
		 	font-family: Arial, sans-serif;
			max-width:80%
			}
			
			.github.td {
				padding-left: 20px;
				padding-right: 20px;
			}

			th {
				
				font-weight: normal;
			}
			
			#toc_container {
			background: #f9f9f9 none repeat scroll 0 0;
			border: 1px solid #aaa;
			display: table;
			font-size: 95%;
			padding-top: 20px;
			padding-left: 20px;
			padding-right: 20px;
			padding-bottom: 8px;
			width: auto;
			}
			
			#toc_container ul  {
			  list-style: outside none none !important; margin-left: -40px;
			}
			
			.id {
			width: 245px;
			}
			
			.ood {
			width: 280px;
			}
			
			.first-col {
			padding-right: 20px;
			white-space: nowrap;
			}
				
		  .text {
			font-style: italic;
			color: #666666;
		  }
		  audio {
      width: 100%;
      max-width: 100%;
	  min-width: 130px;

     
   	 	}
		img {
			width: 300px;
    }
			
		</style>
	</head>
	
	<body>
		<article>
			<header>
				<h1>The Drum Machine of Tao ☯︎</h1>
			</header>
		</article>
		
		<div style="margin-bottom: 16px;" class="github">
			<table>
					<tbody>
						<tr>
							<td><a href="https://nime.org/proceedings/2025/nime2025_79.pdf">[arXiv]</a></td>
							<td><a href="https://github.com/red-x-silver/tao">[GitHub Repo]</a></td>
						</tr>
					</tbody>
			</table>
		</div>
		
		
		<div>
			<p><img src="img/tao-banner.png" alt="banner img of Tao" /></p>
			<b>❍ What we have done:</b> 
			<p> In this work we present <i>Tao</i> , a "symmetric" drum machine capable of both synthesizing audio waveforms from sequencer parameters as well as inferring sequencer parameters from audio waveforms.</p>
			<p> Implementation for "sequencer parameters → audio waveforms" synthesis is not a standing problem; the main challenge of <i>Tao</i>  lies in the reverse direction—"audio waveforms → sequencer parameter"—which we refer to as the sequencer parameter estimation problem. We leverage machine learning to assist with this; see the paper for technical details.</p>
			<b>❍ Why:</b> 
			<p> Recovering sequencer parameters from a sampled drum loop in audio waveform can restore low-level editability to loops that would otherwise remain frozen as audio. The philosophy behind this system draws inspiration from Taoism: that which returns to its primal state follows the great Way of Tao. </p>
			<b>❍ btw:</b> 
			<p>Sequencer parameters (minimal): 
				<ul>
					<li><a> a global tempo</a>
					<li><a> step vectors per each percussive track (e.g. a step vector for the kick drum may look like [1,0,0,0,1,0,0,0])</a>
					<li><a> one-shot samples per each percussive track </a>
				</ul>
			<b>❍ On another note,</b> 
			<p> 
				While the interface of <i>Tao</i> is still under construction, you are invited to imagine an interactive web-based regular drum machine + sequencer interface which probably looks like <a href="https://roland50.studio/">this</a>, but with an additional ⇪drum loop audio file upload section⇪.
			</p>

			
			<b> ❍ Finally: </b> 
			<p>See below for examples of sequencer parameters recovered by <i>Tao</i> from input drum loops. Desktop recommended for optimal display.</p>
			<h4>✻ Example I:</h4>
			<p style="font-weight: bold;">input:</p>
				<table>
					<tr>
						<th> a drum loop </th>
					</tr>
					<tr>
						<td><audio controls preload="none"><source src="wavs/loop111/loop111_bpm190.wav"></audio></td>
					</tr>
					<tr>
						<th></th>
					</tr>
				</table>
				<p style="font-weight: bold;"><i>Tao</i> output: </p>
			
			<table>
				<tbody>
					<tr>
						<th>est. tempo: </th>
						<td style="font-weight: bold; text-align: left;"> 190</td>
					  </tr>
					  <tr><td></td></tr>
					  <tr><td></td></tr>
					  <tr><td></td></tr>
					<th></th>
					<th>extracted one-shot sample</th>
					<th>estimated step vector</th>
				  </tr>
				  <tr>
					<th>🀙 kick:</th>
					<td><audio controls preload="none"><source src="wavs/loop111/kick_one_shot.wav"></audio></td>
					<td style="font-size: 30px;">● ○ ○ ○ ● ○ ○ ○</td>
				  </tr>

				  <tr>
					<th>🀄︎ snare: </th>
					<td><audio controls preload="none"><source src="wavs/loop111/snare_one_shot.wav"></audio></td>
					<td style="font-size: 30px;">○ ○ ○ ○ ● ● ○ ○</td>
				  </tr>

				  <tr>
					<th>🀑 hihats: </th>
					<td><audio controls preload="none"><source src="wavs/loop111/hh_one_shot.wav"></audio></td>
					<td style="font-size: 30px;">○ ● ● ● ● ● ● ●</td>
				  </tr>



				  <tr>
					<th> reconstruction </th>
					<td><audio controls preload="none"><source src="wavs/loop111/reconstructed_loop.wav"></audio></td>				
				</tr>
			  <tr>

				</tbody>
			</table>
			<p>"reconstruction" is the drum loop audio synthesized using the estimated sequencer parameters, provided for a quick assessment on the estimation quality.</p>


			<h4>✻✻ Example II:</h4>
			<p style="font-weight: bold;">input:</p>
				<table>
					<tr>
						<th> a drum loop </th>
					</tr>
					<tr>
						<td><audio controls preload="none"><source src="wavs/loop998/loop998_bpm71.wav"></audio></td>
					</tr>
					<tr>
						<th></th>
					</tr>
				</table>
				<p style="font-weight: bold;"><i>Tao</i> output: </p>
			
			<table>
				<tbody>
					<tr>
						<th>est. tempo: </th>
						<td style="font-weight: bold; text-align: left;"> 71</td>
					  </tr>
					  <tr><td></td></tr>
					  <tr><td></td></tr>
					  <tr><td></td></tr>
					<th></th>
					<th>extracted one-shot sample</th>
					<th>estimated step vector</th>
				  </tr>
				  <tr>
					<th>🀙 kick: </th>
					<td><audio controls preload="none"><source src="wavs/loop998/kick_one_shot.wav"></audio></td>
					<td style="font-size: 30px;">● ○ ● ● ○ ○ ○ ○</td>
				  </tr>

				  <tr>
					<th>🀄︎ snare: </th>
					<td><audio controls preload="none"><source src="wavs/loop998/snare_one_shot.wav"></audio></td>
					<td style="font-size: 30px;">● ● ● ● ○ ● ● ●</td>
				  </tr>

				  <tr>
					<th>🀑 hihats: </th>
					<td><audio controls preload="none"><source src="wavs/loop998/hh_one_shot.wav"></audio></td>
					<td style="font-size: 30px;">● ● ○ ○ ● ● ○ ○</td>
				  </tr>



				  <tr>
					<th> reconstruction </th>
					<td><audio controls preload="none"><source src="wavs/loop998/reconstructed_loop.wav"></audio></td>
				</tr>


			  <tr>

				</tbody>
			</table>
			<p>"reconstruction" is the drum loop audio synthesized using the estimated sequencer parameters, provided for a quick assessment on the estimation quality.</p>

			<h4>✻✻✻ Example III:</h4>
			<p style="font-weight: bold;">input:</p>
				<table>
					<tr>
						<th> a drum loop </th>
					</tr>
					<tr>
						<td><audio controls preload="none"><source src="wavs/loop1140/loop1140_bpm159.wav"></audio></td>
					</tr>
					<tr>
						<th></th>
					</tr>
				</table>
				<p style="font-weight: bold;"><i>Tao</i> output: </p>
			
			<table>
				<tbody>
					<tr>
						<th>est. tempo: </th>
						<td style="font-weight: bold; text-align: left;"> 159</td>
					  </tr>
					  <tr><td></td></tr>
					  <tr><td></td></tr>
					  <tr><td></td></tr>
					<th></th>
					<th>extracted one-shot sample</th>
					<th>estimated step vector</th>
				  </tr>
				  <tr>
					<th>🀙 kick:</th>
					<td><audio controls preload="none"><source src="wavs/loop1140/kick_one_shot.wav"></audio></td>
					<td style="font-size: 30px;">● ○ ○ ● ○ ○ ○ ○</td>
				  </tr>

				  <tr>
					<th>🀄︎ snare: </th>
					<td><audio controls preload="none"><source src="wavs/loop1140/snare_one_shot.wav"></audio></td>
					<td style="font-size: 30px;">● ○ ● ● ○ ○ ● ●</td>
				  </tr>

				  <tr>
					<th>🀑 hihats: </th>
					<td><audio controls preload="none"><source src="wavs/loop1140/hh_one_shot.wav"></audio></td>
					<td style="font-size: 30px;">● ● ● ● ● ● ● ●</td>
				  </tr>



				  <tr>
					<th> reconstruction </th>
					<td><audio controls preload="none"><source src="wavs/loop1140/reconstructed_loop.wav"></audio></td>
				</tr>
			  <tr>

				</tbody>
			</table>
			<p>"reconstruction" is the drum loop audio synthesized using the estimated sequencer parameters, provided for a quick assessment on the estimation quality.</p>

			<h4>✻✻✻✻ Example IV:</h4>
			<p style="font-weight: bold;">input:</p>
				<table>
					<tr>
						<th> a drum loop </th>
					</tr>
					<tr>
						<td><audio controls preload="none"><source src="wavs/loop30/loop30_bpm100.wav"></audio></td>
					</tr>
					<tr>
						<th></th>
					</tr>
				</table>
				<p style="font-weight: bold;"><i>Tao</i> output: </p>
			
			<table>
				<tbody>
					<tr>
						<th>est. tempo: </th>
						<td style="font-weight: bold; text-align: left;"> 100</td>
					  </tr>
					  <tr><td></td></tr>
					  <tr><td></td></tr>
					  <tr><td></td></tr>
					<th></th>
					<th>extracted one-shot sample</th>
					<th>estimated step vector</th>
				  </tr>
				  <tr>
					<th>🀙 kick:</th>
					<td><audio controls preload="none"><source src="wavs/loop30/kick_one_shot.wav"></audio></td>
					<td style="font-size: 30px;">● ● ● ● ● ● ● ●</td>
				  </tr>

				  <tr>
					<th>🀙 kick:</th>
					<td><audio controls preload="none"><source src="wavs/loop30/snare_one_shot.wav"></audio></td>
					<td style="font-size: 30px;">○ ○ ○ ● ○ ○ ○ ●</td>
				  </tr>

				  <tr>
					<th>🀑 hihats: </th>
					<td><audio controls preload="none"><source src="wavs/loop30/hh_one_shot.wav"></audio></td>
					<td style="font-size: 30px;">● ● ● ● ● ● ● ●</td>
				  </tr>



				  <tr>
					<th> reconstruction </th>
					<td><audio controls preload="none"><source src="wavs/loop30/reconstructed_loop.wav"></audio></td>
				</tr>
			  <tr>

				</tbody>
			</table>
			<p>"reconstruction" is the drum loop audio synthesized using the estimated sequencer parameters, provided for a quick assessment on the estimation quality.</p>

			<h4>✻✻✻✻✻ Example V:</h4>
			<p style="font-weight: bold;">input:</p>
				<table>
					<tr>
						<th> a drum loop </th>
					</tr>
					<tr>
						<td><audio controls preload="none"><source src="wavs/loop1798/loop1798_bpm180.wav"></audio></td>
					</tr>
					<tr>
						<th></th>
					</tr>
				</table>
				<p style="font-weight: bold;"><i>Tao</i> output: </p>
			
			<table>
				<tbody>
					<tr>
						<th>est. tempo: </th>
						<td style="font-weight: bold; text-align: left;"> 180</td>
					  </tr>
					  <tr><td></td></tr>
					  <tr><td></td></tr>
					  <tr><td></td></tr>
					<th></th>
					<th>extracted one-shot sample</th>
					<th>estimated step vector</th>
				  </tr>
				  <tr>
					<th>🀙 kick:</th>
					<td><audio controls preload="none"><source src="wavs/loop1798/kick_one_shot.wav"></audio></td>
					<td style="font-size: 30px;">● ○ ○ ○ ● ○ ○ ○</td>
				  </tr>

				  <tr>
					<th>🀄︎ snare: </th>
					<td><audio controls preload="none"><source src="wavs/loop1798/snare_one_shot.wav"></audio></td>
					<td style="font-size: 30px;">● ● ○ ● ○ ○ ● ●</td>
				  </tr>

				  <tr>
					<th>🀑 hihats: </th>
					<td><audio controls preload="none"><source src="wavs/loop1798/hh_one_shot.wav"></audio></td>
					<td style="font-size: 30px;">● ● ● ● ● ○ ● ●</td>
				  </tr>



				  <tr>
					<th> reconstruction </th>
					<td><audio controls preload="none"><source src="wavs/loop1798/reconstructed_loop.wav"></audio></td>
				</tr>
			  <tr>

				</tbody>
			</table>
			<p>"reconstruction" is the drum loop audio synthesized using the estimated sequencer parameters, provided for a quick assessment on the estimation quality.</p>

		</div>
		

		<div><b>❍ Computational evaluation</b> </div>
		

			<div id="toc_container" style="padding-top:0px; max-width: 80%;">
				<div>
					<p>There are different computational metrics for different components as each component in <i>Tao</i> handles a different subproblem.</p>
					<p>We have synthesized two testing drum loops sets fom <a href="https://zenodo.org/records/4687854">Freesound One-Shot Percussive Sounds</a> - a random-rhythm testing set and a prior-rhythm testing set.  </p>
					<p><b>Random-rhythm</b> testing set (<i>Random</i>): the testing set synthesized using randomly sampled step vectors following no prior rhythmic patterns.</p>
					<p><b>Prior-rhythm</b> testing set (<i>Prior</i>): the testing set synthesized using prior step vector collections (one collection for each percussive track), which are prepared by manual annotation from invited professional drummers and producers. </p>
					<p>All one-shot samples in the testing set were unseen during training. </p>
				</div>
			<ul>
				<li><a href="#eval-dss"> 1. Evaluation results of the drum source separation model</a>
				<li><a href="#eval-tempo"> 2. Evaluation results of the tempo estimation</a>
				<li><a href="#eval-sv"> 3. Evaluation results of the step vector estimation</a>
				<li><a href="#eval-oneshot"> 4. Evaluation results of the one-shot sample extraction</a>
	

			</ul>
		</div>
		
		<div>

			<a name="eval-dss"><h4>1. Evaluation results of the drum source separation model</h4></a>
			<p>We adopt the commonly used Music Source Separation evaluation metrics including the Signal-to-Distortion Ratio (SDR) and the Scale-Invariant Signal-to-Distortion Ratio (SI-SDR).</p>
			<table>
				<tbody>
				  <tr>
					<th style="font-weight: bold;">Metrics (in dB)</th>
					<th style="font-weight: bold;">kick</th>
					<th style="font-weight: bold;">snare</th>
					<th style="font-weight: bold;">hihats</th>
				  </tr>
				  <tr>
					<td>SDR (Prior)</td>
					<td>17.09</td>
					<td>7.32</td>
					<td>4.97</td>
				  </tr>
				  <tr>
					<td>SI-SDR (Prior) </td>
					<td>15.34</td>
					<td>6.00 </td>
					<td>2.77</td>
				  </tr>
				  <tr>
					<td>SDR (Random) </td>
					<td>15.84 </td>
					<td>8.40 </td>
					<td>3.60</td>
				  </tr>
				  <tr>
					<td>SI-SDR (Random)</td>
					<td>14.33</td>
					<td>7.37</td>
					<td>0.43</td>
				  </tr>
				</tbody>
			</table>

			<a name="eval-tempo"><h4>2. Evaluation results of the tempo estimation</h4></a>
			<p>We adopt accuracy metric which is computed if the estimated tempo is within 1% of the groundtruth tempo. </p>
			<table>
				<tbody>
					<tr>
					<th style="font-weight: bold;">Metrics</th>
					<th style="font-weight: bold;"></th>
					</tr>
				  <tr>
					<td>Accuracy (Prior)</td>
					<td>0.995</td>

				  </tr>
				  <tr>
					<td>Accuracy (Random)</td>
					<td>0.999</td>

				  </tr>
			</table>

			<a name="eval-sv"><h4>3. Evaluation results of the step vector estimation</h4></a>
			<p>For evaluating the estimated step vectors, we propose to use recall, precision and F-measure metrics considering it being a multi-label binary classification task.</p>
			<table>
				<tbody>
				  <tr>
					<th style="font-weight: bold;">Metrics</th>
					<th style="font-weight: bold;">kick</th>
					<th style="font-weight: bold;">snare</th>
					<th style="font-weight: bold;">hihats</th>
				  </tr>
				  <tr>
					<td>F-measure(Prior) </td>
					<td>0.903</td>
					<td>0.770 </td>
					<td>0.861</td>
				  </tr>
				  <tr>
					<td>F-measure(Random) </td>
					<td>0.908</td>
					<td>0.860</td>
					<td>0.813</td>
				  </tr>
				</tbody>
			</table>

			<a name="eval-oneshot"><h4>4. Evaluation results of the one-shot sample extraction</h4></a>
			<p>for evaluating the quality of the extracted one-shot sample waveforms compared to the groundtruth ones used for loop synthesis, we propose to use the SDR and the SI-SDR metrics.</p>
			<table>
				<tbody>
				  <tr>
					<th style="font-weight: bold;">Metrics (in dB)</th>
					<th style="font-weight: bold;">kick</th>
					<th style="font-weight: bold;">snare</th>
					<th style="font-weight: bold;">hihats</th>
				  </tr>
				  <tr>
					<td>SDR (Prior)</td>
					<td>48.21 </td>
					<td>15.23 </td>
					<td>29.29 </td>
				  </tr>
				  <tr>
					<td>SI-SDR (Prior) </td>
					<td>40.62 </td>
					<td>20.31 </td>
					<td>20.31(?) </td>
				  </tr>
				  <tr>
					<td>SDR (Random) </td>
					<td>37.80  </td>
					<td>33.35 </td>
					<td>25.36 </td>
				  </tr>
				  <tr>
					<td>SI-SDR (Random)</td>
					<td>31.47</td>
					<td>21.98</td>
					<td>15.42</td>
				  </tr>
				</tbody>
			</table>
		</div>

		<div><b>❍ Dataset used for training the sequencer parameter estimation model: </b> 
		<p>With no sequencer-info annotated drum loops dataset available in the public domain, we design a data synthesis pipeline in <i>Tao</i> utilizing the publicly available one-shot sample dataset <a href="https://zenodo.org/records/4687854">Freesound One-Shot Percussive Sounds</a>. </p>
		<p>We synthesize drum loops using the one-shot samples and randomly generated step vectors and tempo.</p>
		<p>The synthesis pipeline is built on 1D convolution which is differentiable and parallelizable; theoretically infinitely many annotated drum loops can be synthesized during training on-the-fly.</p>
		</div>

		<div><b>❍ Ethical Standards</b> 
			<p>This paper does not involve experiments with human or animal
				participants. Datasets used for training machine learning models
				in this paper are acquired from open access datasets.</p>

		<div><b>❍ Acknowledgments</b> 
		<p>This work is funded by UK Research and Innovation [grant number EP/S022694/1] as part of the “UKRI Centre for Doctoral Training in Artificial Intelligence and Music”.</p>
		
	</body>
	

</html>
